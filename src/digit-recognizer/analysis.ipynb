{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    Conv2D,\n",
    "    MaxPool2D,\n",
    "    AvgPool2D,\n",
    "    BatchNormalization,\n",
    "    Reshape,\n",
    ")\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# LOAD THE DATA\n",
    "train = pd.read_csv(\"datasets/train.csv.zip\", compression=\"zip\", header=0)\n",
    "test = pd.read_csv(\"datasets/test.csv.zip\", compression=\"zip\", header=0)\n",
    "\n",
    "# PREPARE DATA FOR NEURAL NETWORK\n",
    "Y_train = train[\"label\"]\n",
    "X_train = train.drop(labels=[\"label\"], axis=1)\n",
    "X_train = X_train / 255.0\n",
    "X_test = test / 255.0\n",
    "X_train = X_train.values.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.values.reshape(-1, 28, 28, 1)\n",
    "Y_train = to_categorical(Y_train, num_classes=10)\n",
    "\n",
    "# GLOBAL VARIABLES\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95**x, verbose=0)\n",
    "styles = [\":\", \"-.\", \"--\", \"-\", \":\", \"-.\", \"--\", \"-\", \":\", \"-.\", \"--\", \"-\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nets = 3\n",
    "model = [0] * nets\n",
    "\n",
    "for j in range(nets):\n",
    "    model[j] = Sequential()\n",
    "    model[j].add(\n",
    "        Conv2D(\n",
    "            filters=24,\n",
    "            kernel_size=5,\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "            input_shape=(28, 28, 1),\n",
    "        )\n",
    "    )\n",
    "    model[j].add(MaxPool2D())\n",
    "    if j > 0:\n",
    "        model[j].add(Conv2D(48, kernel_size=5, padding=\"same\", activation=\"relu\"))\n",
    "        model[j].add(MaxPool2D())\n",
    "    if j > 1:\n",
    "        model[j].add(Conv2D(64, kernel_size=5, padding=\"same\", activation=\"relu\"))\n",
    "        model[j].add(MaxPool2D(padding=\"same\"))\n",
    "    model[j].add(Flatten())\n",
    "    model[j].add(Dense(256, activation=\"relu\"))\n",
    "    model[j].add(Dense(10, activation=\"softmax\"))\n",
    "    model[j].compile(\n",
    "        optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE VALIDATION SET\n",
    "X_train2, X_val2, Y_train2, Y_val2 = train_test_split(X_train, Y_train, test_size=0.333)\n",
    "# TRAIN NETWORKS\n",
    "history = [0] * nets\n",
    "names = [\"(C-P)x1\", \"(C-P)x2\", \"(C-P)x3\"]\n",
    "epochs = 2\n",
    "hist = model[j].fit(\n",
    "        X_train2,\n",
    "        Y_train2,\n",
    "        batch_size=80,\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_val2, Y_val2),\n",
    "        callbacks=[annealer],\n",
    "        verbose=0,\n",
    "    )\n",
    "h = hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE VALIDATION SET\n",
    "X_train2, X_val2, Y_train2, Y_val2 = train_test_split(X_train, Y_train, test_size=0.333)\n",
    "# TRAIN NETWORKS\n",
    "history = [0] * nets\n",
    "names = [\"(C-P)x1\", \"(C-P)x2\", \"(C-P)x3\"]\n",
    "epochs = 20\n",
    "for j in range(nets):\n",
    "    history[j] = model[j].fit(\n",
    "        X_train2,\n",
    "        Y_train2,\n",
    "        batch_size=80,\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_val2, Y_val2),\n",
    "        callbacks=[annealer],\n",
    "        verbose=0,\n",
    "    )\n",
    "    print(\n",
    "        \"CNN {0}: Epochs={1:d}, Train accuracy={2:.5f}, Validation accuracy={3:.5f}\".format(\n",
    "            names[j],\n",
    "            epochs,\n",
    "            max(history[j].history[\"accuracy\"]),\n",
    "            max(history[j].history[\"val_accuracy\"]),\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT ACCURACIES\n",
    "plt.figure(figsize=(15,5))\n",
    "for i in range(nets):\n",
    "    plt.plot(history[i].history['val_accuracy'],linestyle=styles[i])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(names, loc='upper left')\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.98,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD CONVOLUTIONAL NEURAL NETWORKS\n",
    "nets = 6\n",
    "model = [0] * nets\n",
    "for j in range(6):\n",
    "    model[j] = Sequential()\n",
    "    model[j].add(\n",
    "        Conv2D(j * 8 + 8, kernel_size=5, activation=\"relu\", input_shape=(28, 28, 1))\n",
    "    )\n",
    "    model[j].add(MaxPool2D())\n",
    "    model[j].add(Conv2D(j * 16 + 16, kernel_size=5, activation=\"relu\"))\n",
    "    model[j].add(MaxPool2D())\n",
    "    model[j].add(Flatten())\n",
    "    model[j].add(Dense(256, activation=\"relu\"))\n",
    "    model[j].add(Dense(10, activation=\"softmax\"))\n",
    "    model[j].compile(\n",
    "        optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE VALIDATION SET\n",
    "X_train2, X_val2, Y_train2, Y_val2 = train_test_split(X_train, Y_train, test_size=0.333)\n",
    "# TRAIN NETWORKS\n",
    "history = [0] * nets\n",
    "names = [\"8 maps\", \"16 maps\", \"24 maps\", \"32 maps\", \"48 maps\", \"64 maps\"]\n",
    "epochs = 20\n",
    "for j in range(nets):\n",
    "    history[j] = model[j].fit(\n",
    "        X_train2,\n",
    "        Y_train2,\n",
    "        batch_size=80,\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_val2, Y_val2),\n",
    "        callbacks=[annealer],\n",
    "        verbose=0,\n",
    "    )\n",
    "    print(\n",
    "        \"CNN {0}: Epochs={1:d}, Train accuracy={2:.5f}, Validation accuracy={3:.5f}\".format(\n",
    "            names[j],\n",
    "            epochs,\n",
    "            max(history[j].history[\"accuracy\"]),\n",
    "            max(history[j].history[\"val_accuracy\"]),\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT ACCURACIES\n",
    "plt.figure(figsize=(15,5))\n",
    "for i in range(nets):\n",
    "    plt.plot(history[i].history['val_accuracy'],linestyle=styles[i])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(names, loc='upper left')\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.98,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD CONVOLUTIONAL NEURAL NETWORKS\n",
    "nets = 8\n",
    "model = [0] * nets\n",
    "\n",
    "for j in range(8):\n",
    "    model[j] = Sequential()\n",
    "    model[j].add(Conv2D(32, kernel_size=5, activation=\"relu\", input_shape=(28, 28, 1)))\n",
    "    model[j].add(MaxPool2D())\n",
    "    model[j].add(Conv2D(64, kernel_size=5, activation=\"relu\"))\n",
    "    model[j].add(MaxPool2D())\n",
    "    model[j].add(Flatten())\n",
    "    if j > 0:\n",
    "        model[j].add(Dense(2 ** (j + 4), activation=\"relu\"))\n",
    "    model[j].add(Dense(10, activation=\"softmax\"))\n",
    "    model[j].compile(\n",
    "        optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE VALIDATION SET\n",
    "X_train2, X_val2, Y_train2, Y_val2 = train_test_split(X_train, Y_train, test_size=0.333)\n",
    "# TRAIN NETWORKS\n",
    "history = [0] * nets\n",
    "names = [\"0N\", \"32N\", \"64N\", \"128N\", \"256N\", \"512N\", \"1024N\", \"2048N\"]\n",
    "epochs = 20\n",
    "for j in range(nets):\n",
    "    history[j] = model[j].fit(\n",
    "        X_train2,\n",
    "        Y_train2,\n",
    "        batch_size=80,\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_val2, Y_val2),\n",
    "        callbacks=[annealer],\n",
    "        verbose=0,\n",
    "    )\n",
    "    print(\n",
    "        \"CNN {0}: Epochs={1:d}, Train accuracy={2:.5f}, Validation accuracy={3:.5f}\".format(\n",
    "            names[j],\n",
    "            epochs,\n",
    "            max(history[j].history[\"accuracy\"]),\n",
    "            max(history[j].history[\"val_accuracy\"]),\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT ACCURACIES\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i in range(nets):\n",
    "    plt.plot(history[i].history[\"val_accuracy\"], linestyle=styles[i])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend(names, loc=\"upper left\")\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.98, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD CONVOLUTIONAL NEURAL NETWORKS\n",
    "nets = 8\n",
    "model = [0] * nets\n",
    "\n",
    "for j in range(nets):\n",
    "    model[j] = Sequential()\n",
    "    model[j].add(Conv2D(32, kernel_size=5, activation=\"relu\", input_shape=(28, 28, 1)))\n",
    "    model[j].add(MaxPool2D())\n",
    "    model[j].add(Dropout(j * 0.1))\n",
    "    model[j].add(Conv2D(64, kernel_size=5, activation=\"relu\"))\n",
    "    model[j].add(MaxPool2D())\n",
    "    model[j].add(Dropout(j * 0.1))\n",
    "    model[j].add(Flatten())\n",
    "    model[j].add(Dense(128, activation=\"relu\"))\n",
    "    model[j].add(Dropout(j * 0.1))\n",
    "    model[j].add(Dense(10, activation=\"softmax\"))\n",
    "    model[j].compile(\n",
    "        optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE VALIDATION SET\n",
    "X_train2, X_val2, Y_train2, Y_val2 = train_test_split(X_train, Y_train, test_size=0.333)\n",
    "# TRAIN NETWORKS\n",
    "history = [0] * nets\n",
    "names = [\"D=0\", \"D=0.1\", \"D=0.2\", \"D=0.3\", \"D=0.4\", \"D=0.5\", \"D=0.6\", \"D=0.7\"]\n",
    "epochs = 30\n",
    "for j in range(nets):\n",
    "    history[j] = model[j].fit(\n",
    "        X_train2,\n",
    "        Y_train2,\n",
    "        batch_size=80,\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_val2, Y_val2),\n",
    "        callbacks=[annealer],\n",
    "        verbose=0,\n",
    "    )\n",
    "    print(\n",
    "        \"CNN {0}: Epochs={1:d}, Train accuracy={2:.5f}, Validation accuracy={3:.5f}\".format(\n",
    "            names[j],\n",
    "            epochs,\n",
    "            max(history[j].history[\"accuracy\"]),\n",
    "            max(history[j].history[\"val_accuracy\"]),\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT ACCURACIES\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i in range(nets):\n",
    "    plt.plot(history[i].history[\"val_accuracy\"], linestyle=styles[i])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend(names, loc=\"upper left\")\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.98, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN OUR BEST NET MORE\n",
    "datagen = ImageDataGenerator(\n",
    "    zoom_range=0.1, height_shift_range=0.1, width_shift_range=0.1, rotation_range=10\n",
    ")\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** (x + epochs))\n",
    "model[4].fit_generator(\n",
    "    datagen.flow(X_train, Y_train, batch_size=64),\n",
    "    epochs=25,\n",
    "    steps_per_epoch=X_train.shape[0] // 64,\n",
    "    callbacks=[annealer],\n",
    "    verbose=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUBMIT TO KAGGLE\n",
    "results = model[4].predict(X_test)\n",
    "results = np.argmax(results, axis=1)\n",
    "results = pd.Series(results, name=\"Label\")\n",
    "submission = pd.concat([pd.Series(range(1, 28001), name=\"ImageId\"), results], axis=1)\n",
    "submission.to_csv(\"datasets/submission.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d06ee931ab140b5c25de85b8d5dd49f04a6c55425a1ce9a3c19ed9be6600fe63"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
